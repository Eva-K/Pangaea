---
title: "Spreadsheet Wrangling"
author: "E. Kovacs"
date: "22 July 2019"
output: html_document
---

# Trying to tidy up and Manipulate spreadsheets/text files.

```{r}
install.packages("data.table")

library(tidyverse)
library(data.table)

```

# Read in the Data 

```{r read in text files}

# set working directory desktop
#setwd("C:/Users/uqekovac/Documents/R/Pangaea/Pangaea")

# Laptop
setwd("/Users/evam-k/Desktop/Coding/Pangaea/Pangaea")

# THIS NEXT SECTION DOES NOT WORK - see below
# Get the file names

temp = list.files(pattern = "*.csv") 

photos <- lapply(temp, read.delim) # each file as a sub of photos
# not working on laptop - the embedded NULLS thing again....
rm(photos)

filelist <- list.files(pattern = "*.*.csv") # lists all the files in the directory

filelist

# do all at once - read and bind

SGBR <- do.call(rbind, lapply(temp, read.delim)) # Errors generated saying line "x" appears to contain embedded nulls


# merge these files into a single dataframe
 
for (file in filelist({
  # if the merged dataset doesn't exist then create it
  if (!exists("SGBRpangaea")){
    SGBRpangaea <- read.table(file, header = TRUE, sep = "\t")
  }
  # if the merged dataset does exist then append to it
  if (exists("SGBRpangaea")){
    temp_dataset <- read.table(file, header = TRUE, sep = "\t")
    SGBRpangaea <- rbind(SGBRpangaea, temp_dataset)
    rm(temp_dataset)
  }
})) ## ERROR - unexpected end of document

```

# read in a single file FIRST - find out encoding and read again!

```{r Trying to solve the embedded nulls}

# setwd("C:/Users/uqekovac/Documents/R/Pangaea/Pangaea")

D21 <- read.csv("C:/Users/uqekovac/Documents/R/Pangaea/Pangaea/d21.csv") 
# generating embedded  nulls error again

# guess encoding
guess_encoding("C:/Users/uqekovac/Documents/R/Pangaea/Pangaea/d21.csv", n_max = 1000)

  ## says UTF-16LE

# Try reading again
D21 <- read.csv("C:/Users/uqekovac/Documents/R/Pangaea/Pangaea/d21.csv", fileEncoding = "UTF-16LE") 

  ## Worked!!


```

# Try reading all files in as per before
# this time stipulating the encoding
# and bind into one dataframe

```{r read all files with correct encoding}

temp = list.files(pattern = "*.csv") 

photos <- lapply(temp, read.delim, fileEncoding = "UTF-16LE") # each file as a sub of photos 
  
  ## Yay! Worked. But is a list of dataframes

# Try read and bind into a single dataframe
SGBR <- do.call(rbind, lapply(temp, read.delim, fileEncoding = "UTF-16LE"))

  ## Worked - one dataframe with all photos listed

```

# Data wrangling - to photo name only

```{r try to cut down the file names to not be a path just a photo name}

head(SGBR)
colnames(SGBR)

# Try separating the long names into something else based on removing the first 107 characters

SGBR2 <- separate(SGBR$X.TYPE.Selected.System.IO.DirectoryInfo, c("Path", "PhotoName"), sep = 107)

# These are factors so convert to characters

SGBR$X.TYPE.Selected.System.IO.DirectoryInfo <- as.character(SGBR$X.TYPE.Selected.System.IO.DirectoryInfo)

# Now run separate code

SGBR2 <- separate(SGBR$X.TYPE.Selected.System.IO.DirectoryInfo, names = c("Path", "PhotoName"), sep = 107)

# not running on character vector (STUPID) - need to use the column name

# Doesn't have one so make one

colnames(SGBR) <- c("Path")

# Let's try splitting again
# as above

SGBR2 <- separate(SGBR$Path, names = c("Path", "PhotoName"), sep = 107)
# Not working

# Try 
SGBR2 <- separate(SGBR, "Path", c("Path", "PhotoName"), sep = 107)

# 107 is too many (x 10)
# Try
SGBR2 <- separate(SGBR, "Path", c("Path", "PhotoName"), sep = 97)

# Each name seems to be variable - probably based on the variability in the path string
# Try splitting the photoname column by the "\"
# HOWEVER to have special meanings \ and ^

  ## Need to escape the backslashes but they need a DOUBLE escape as a backslash is an escape :/

SGBR3 <- separate(SGBR2, "PhotoName", c(NA, "Photo"), sep = "\\\\")

# Has worked except for names where there was no \ 
# Here it has returned NA

SGBR3b <- na.omit(SGBR3)

# This appears to have worked
# Now how to get rid of the long names in SGBR2...??

# Go back a couple of steps: separate PhotoName into two columns
# One with the \ names and one with the already good names

SGBR4 <- separate(SGBR2, "PhotoName", c("PN", "Photo"), sep = "\\\\")

# That's an interesting output - now the letters occurring before the \
# have been placed in the same column as those names that had no \
# whilst what followed the \ has gone into another column!

# Should now be able to remove rows based on the two characters (depending on how many there are...)

# No - more complicated cause now some of the names don't make any sense
# as they are missing dates etc
# This has been wrong since SGBR2 :( 

```

# Using new found knowledge, let's separate based on \

```{r Separating based on special characters}

# Photo paths are like this:
# \\sees-rsrc\Data\3DGBR_HabMap\Data_field\201905GBRSouth\Phototransects\20190601\DiveCorrectLinks\20190601_Showe_D3 (1).jpg"

# Don't give useless data columns NA as a header - use something else

BigSGBR <- separate(SGBR, "Path", c("Nope", "No", "UQ", "Data", "What", "Where", "When", "How", "Date", "Folder", "PhotoName"), sep = "\\\\")

# Has worked.
# For whatever reason the \\ at the beginning of the path was being treated as two columns.
# Just added to NA columns to hold these.

```

# Getting rid of unwanted rows and columns

```{r the == function will pick up any NA records as well as "hesc", whereas %in% won't}

## the == function will pick up any NA records as well as "hesc", whereas %in% won't
BigSGBR2 <- select(BigSGBR, -c(1,2))

# Worked.

# Now remove the rows full of NA's and Esc in "No"

BigSGBR3 <- na.omit(BigSGBR2)

# Now remove rows that have non-photo elements

BigSGBR4 <- subset(BigSGBR3, PhotoName == "Exc")

# This returns a df with only those rows in it

BigSGBR4 <- subset(BigSGBR3, PhotoName != "Exc")

# This has worked.

# Are there any other rows with text file names or additional folder names??

photonames <- unique(BigSGBR4$PhotoName) # too long

# try selecting based on starting with 2

trial <- tidyselect::vars_select(names(BigSGBR4$PhotoName), starts_with('2', ignore.case = TRUE)) 
# Nope - error - no tidyset variables were registered.

trial <- subset(BigSGBR4, starts_with("2"))
# Nope

trial <- subset(BigSGBR4, BigSGBR4$PhotoName != starts_with("2"))

```
# Write to csv
```{r write to file}

write.table(BigSGBR4, "BigSGBR4.csv", sep="\t")

```

